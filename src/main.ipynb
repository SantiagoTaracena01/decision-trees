{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universidad del Valle de Guatemala\n",
    "## (CC3085) Inteligencia Artificial\n",
    "## Laboratorio 6 - Árboles de Decisión\n",
    "\n",
    "Miembros del equipo:\n",
    "- Pedro Pablo Arriola Jiménez (20188)\n",
    "- Oscar Fernando López Barrios (20679)\n",
    "- Yong Bum Park (20117)\n",
    "- Santiago Taracena Puga (20017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       gameId  blueWins  blueWardsPlaced  blueWardsDestroyed  blueFirstBlood  \\\n",
      "0  4519157822         0               28                   2               1   \n",
      "1  4523371949         0               12                   1               0   \n",
      "2  4521474530         0               15                   0               0   \n",
      "3  4524384067         0               43                   1               0   \n",
      "4  4436033771         0               75                   4               0   \n",
      "\n",
      "   blueKills  blueDeaths  blueAssists  blueEliteMonsters  blueDragons  ...  \\\n",
      "0          9           6           11                  0            0  ...   \n",
      "1          5           5            5                  0            0  ...   \n",
      "2          7          11            4                  1            1  ...   \n",
      "3          4           5            5                  1            0  ...   \n",
      "4          6           6            6                  0            0  ...   \n",
      "\n",
      "   redTowersDestroyed  redTotalGold  redAvgLevel  redTotalExperience  \\\n",
      "0                   0         16567          6.8               17047   \n",
      "1                   1         17620          6.8               17438   \n",
      "2                   0         17285          6.8               17254   \n",
      "3                   0         16478          7.0               17961   \n",
      "4                   0         17404          7.0               18313   \n",
      "\n",
      "   redTotalMinionsKilled  redTotalJungleMinionsKilled  redGoldDiff  \\\n",
      "0                    197                           55         -643   \n",
      "1                    240                           52         2908   \n",
      "2                    203                           28         1172   \n",
      "3                    235                           47         1321   \n",
      "4                    225                           67         1004   \n",
      "\n",
      "   redExperienceDiff  redCSPerMin  redGoldPerMin  \n",
      "0                  8         19.7         1656.7  \n",
      "1               1173         24.0         1762.0  \n",
      "2               1033         20.3         1728.5  \n",
      "3                  7         23.5         1647.8  \n",
      "4               -230         22.5         1740.4  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/high_diamond_ranked_10min.csv\")\n",
    "# Ver las primeras filas del dataset\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gameId                          0\n",
       "blueWins                        0\n",
       "blueWardsPlaced                 0\n",
       "blueWardsDestroyed              0\n",
       "blueFirstBlood                  0\n",
       "blueKills                       0\n",
       "blueDeaths                      0\n",
       "blueAssists                     0\n",
       "blueEliteMonsters               0\n",
       "blueDragons                     0\n",
       "blueHeralds                     0\n",
       "blueTowersDestroyed             0\n",
       "blueTotalGold                   0\n",
       "blueAvgLevel                    0\n",
       "blueTotalExperience             0\n",
       "blueTotalMinionsKilled          0\n",
       "blueTotalJungleMinionsKilled    0\n",
       "blueGoldDiff                    0\n",
       "blueExperienceDiff              0\n",
       "blueCSPerMin                    0\n",
       "blueGoldPerMin                  0\n",
       "redWardsPlaced                  0\n",
       "redWardsDestroyed               0\n",
       "redFirstBlood                   0\n",
       "redKills                        0\n",
       "redDeaths                       0\n",
       "redAssists                      0\n",
       "redEliteMonsters                0\n",
       "redDragons                      0\n",
       "redHeralds                      0\n",
       "redTowersDestroyed              0\n",
       "redTotalGold                    0\n",
       "redAvgLevel                     0\n",
       "redTotalExperience              0\n",
       "redTotalMinionsKilled           0\n",
       "redTotalJungleMinionsKilled     0\n",
       "redGoldDiff                     0\n",
       "redExperienceDiff               0\n",
       "redCSPerMin                     0\n",
       "redGoldPerMin                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División del dataset en entrenamiento, validación y prueba\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(data.drop(['blueWins'], axis=1), \n",
    "                                                          data['blueWins'], \n",
    "                                                          test_size=0.1, \n",
    "                                                          random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, \n",
    "                                                  y_trainval, \n",
    "                                                  test_size=0.1, \n",
    "                                                  random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para construir el árbol de decisión\n",
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, value=None, left=None, right=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.value = value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        \n",
    "def build_tree(X, y, max_depth=3, max_features=None, depth=0):\n",
    "    # Si todos los elementos de y son iguales, devolvemos un nodo hoja con ese valor\n",
    "    if len(y.unique()) == 1:\n",
    "        return Node(value=y.iloc[0])\n",
    "    \n",
    "    # Si se alcanza la profundidad máxima, devolvemos un nodo hoja con la clase mayoritaria\n",
    "    if depth == max_depth:  \n",
    "        return Node(value=y.value_counts().idxmax())\n",
    "    \n",
    "    # Seleccionamos la mejor variable de separación y el umbral para dividir los datos\n",
    "    best_feature, best_threshold = select_best_split(X, y, max_features)\n",
    "    \n",
    "    # Dividimos los datos en dos conjuntos, aquellos que cumplen la condición y aquellos que no\n",
    "    left_idx = X[best_feature] < best_threshold\n",
    "    right_idx = X[best_feature] >= best_threshold\n",
    "    \n",
    "    # Construimos los subárboles\n",
    "    left = build_tree(X.loc[left_idx], y.loc[left_idx], max_depth,max_features, depth+1)\n",
    "    right = build_tree(X.loc[right_idx], y.loc[right_idx], max_depth,max_features, depth+1)\n",
    "    \n",
    "    # Devolvemos el nodo raíz del subárbol\n",
    "    return Node(feature=best_feature, threshold=best_threshold, left=left, right=right)\n",
    "\n",
    "def select_best_split(X, y, max_features=None):\n",
    "    n_features = X.shape[1]\n",
    "    if max_features is not None and max_features < n_features:\n",
    "        features = np.random.choice(X.columns, size=max_features, replace=False)\n",
    "    else:\n",
    "        features = X.columns\n",
    "    \n",
    "    best_feature, best_threshold, best_gini = None, None, 1.0\n",
    "    \n",
    "    for feature in features:\n",
    "        for threshold in X[feature].unique():\n",
    "            left_idx = X[feature] < threshold\n",
    "            right_idx = X[feature] >= threshold\n",
    "            left_gini = gini(y.loc[left_idx])\n",
    "            right_gini = gini(y.loc[right_idx])\n",
    "            gini_impurity = (left_gini * sum(left_idx) + right_gini * sum(right_idx)) / len(y)\n",
    "            \n",
    "            if gini_impurity < best_gini:\n",
    "                best_feature = feature\n",
    "                best_threshold = threshold\n",
    "                best_gini = gini_impurity\n",
    "                \n",
    "    return best_feature, best_threshold\n",
    "\n",
    "\n",
    "def gini(y):\n",
    "    # Calculamos la proporción de cada clase en y\n",
    "    p = y.value_counts(normalize=True)\n",
    "    \n",
    "    # Calculamos el índice de Gini\n",
    "    gini = 1 - sum(p**2)\n",
    "    \n",
    "    return gini\n",
    "\n",
    "def predict(x, tree):\n",
    "    # Si llegamos a un nodo hoja, devolvemos la clase correspondiente\n",
    "    if tree.value is not None:\n",
    "        return tree.value\n",
    "    \n",
    "    # Si la instancia cumple la condición del nodo, continuamos por el subárbol izquierdo\n",
    "    if x[tree.feature] < tree.threshold:\n",
    "        return predict(x, tree.left)\n",
    "    \n",
    "    # Si no, continuamos por el subárbol derecho\n",
    "    else:\n",
    "        return predict(x, tree.right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir el árbol de decisión con el conjunto de entrenamiento\n",
    "tree = build_tree(X_train, y_train, max_depth=4, max_features=5)\n",
    "#en este"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer predicciones con el conjunto de validación\n",
    "y_pred = X_val.apply(lambda x: predict(x, tree), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en el conjunto de validación: 0.709\n"
     ]
    }
   ],
   "source": [
    "# Calcular la precisión de las predicciones\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f'Precisión en el conjunto de validación: {accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en el conjunto de validación: 0.734\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cargar los datos\n",
    "data = pd.read_csv(\"./data/high_diamond_ranked_10min.csv\")\n",
    "\n",
    "# División del dataset en entrenamiento, validación y prueba\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(data.drop(['blueWins'], axis=1), \n",
    "                                                          data['blueWins'], \n",
    "                                                          test_size=0.1, \n",
    "                                                          random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, \n",
    "                                                  y_trainval, \n",
    "                                                  test_size=0.1, \n",
    "                                                  random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "clf = DecisionTreeClassifier(max_depth=3, max_features=5, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones con el conjunto de validación\n",
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "# Calcular la precisión de las predicciones\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f'Precisión en el conjunto de validación: {accuracy:.3f}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.709 segun el que hicimos\n",
    "0.734 con el la libreria"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
